{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/mnt/8de37f61-64a8-4a87-8e84-52eef99e123a/thesis/mscemanuelkuhn/code/evaluation/pipeline/\")\n",
    "sys.path.append(\"/mnt/8de37f61-64a8-4a87-8e84-52eef99e123a/thesis/mscemanuelkuhn/code/\")\n",
    "\n",
    "# from step_4_compute_triplet_accuracy import compute_triplet_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/emanuel/Documents/thesis/layoutgmn_reproductions/LayoutGMN-pytorch/\")\n",
    "sys.path.append(\"/home/emanuel/Documents/thesis/layoutgmn_reproductions/LayoutGMN-pytorch/training_scripts\")\n",
    "\n",
    "from cross_graph_communication_5 import GraphMatchingNet\n",
    "from graph_encoder_0 import GraphEncoder, MLP\n",
    "from graph_aggregator_2 import GraphAggregator\n",
    "\n",
    "from util import get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "\n",
    "def download_model_weights_from_wandb(pretrained_wandb_model_ref):\n",
    "\n",
    "    assert wandb.run is not None, \"wandb.run is None; wandb.init() must be called before download_model_weights_from_wandb()\"\n",
    "\n",
    "    model_art: wandb.Artifact = wandb.run.use_artifact(pretrained_wandb_model_ref, type=\"model\")\n",
    "\n",
    "    pretrained_path = model_art.file()\n",
    "\n",
    "    starting_epoch = min(int(model_art.metadata[\"epoch\"]), int(model_art.logged_by().summary[\"epoch\"]))\n",
    "\n",
    "    if starting_epoch < model_art.metadata[\"epoch\"]:\n",
    "        print(f\"WARNING: Loaded model has incorrect epoch metadata: {starting_epoch=} < {model_art.metadata['epoch']=}\")\n",
    "        print(\"Using max epoch of run as starting epoch\")\n",
    "\n",
    "    print(f'Downloaded pretrained model to:  {pretrained_path} (wandb reference: {pretrained_wandb_model_ref})')\n",
    "\n",
    "    return pretrained_path, starting_epoch\n",
    "    \n",
    "\n",
    "def load_pretrained_model(gmn_model, pretrained_path):\n",
    "    '''\n",
    "    :param gmn_model: network model\n",
    "    :param save_dir: path of the dir where the models have been saved\n",
    "    :param stored_epoch: str, ex: '8'\n",
    "    '''\n",
    "    print('Loading pretrained models')\n",
    "    \n",
    "    gmn_model_state_dict = torch.load(pretrained_path)\n",
    "\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    def remove_module_fromStateDict(model_state_dict, model):\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in model_state_dict.items():\n",
    "            name = k[0:]  # if ran on two GPUs, remove 'module.module.'; else, no change\n",
    "            new_state_dict[name] = v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        return model\n",
    "\n",
    "    loaded_gmn_model = remove_module_fromStateDict(gmn_model_state_dict, gmn_model)\n",
    "    print('Finished loading checkpoint')\n",
    "    return loaded_gmn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_args({})\n",
    "\n",
    "encoder_model =  GraphEncoder(config, node_hidden_sizes=[config.node_geometry_feat_dim, config.node_state_dim],\n",
    "                              edge_hidden_sizes=[config.edge_feat_dim, int(config.node_state_dim)])\n",
    "\n",
    "aggregator_model = GraphAggregator(node_hidden_sizes=[config.graph_rep_dim],\n",
    "          config=config,\n",
    "          graph_transform_sizes=[config.graph_rep_dim],\n",
    "          gated=True,\n",
    "          aggregation_type='sum')\n",
    "\n",
    "\n",
    "message_net = MLP([2*config.node_state_dim+int(config.node_state_dim), config.edge_feat_dim, int(config.node_state_dim), int(config.node_state_dim)])\n",
    "reverse_message_net = MLP([2*config.node_state_dim+int(config.node_state_dim), config.edge_feat_dim, int(config.node_state_dim), int(config.node_state_dim)])\n",
    "node_update_mlp = MLP([2*config.node_state_dim+int(config.node_state_dim), config.node_geometry_feat_dim, int(config.node_state_dim), config.node_state_dim])\n",
    "\n",
    "\n",
    "gmn_net = GraphMatchingNet(encoder = encoder_model,\n",
    "               aggregator = aggregator_model,\n",
    "               message_net = message_net,\n",
    "               reverse_message_net = reverse_message_net,\n",
    "               node_update_MLP = node_update_mlp,\n",
    "               node_state_dim = config.node_state_dim,\n",
    "               edge_hidden_sizes = [config.edge_feat_dim, config.node_state_dim * 2,\n",
    "                                    config.node_state_dim * 2],\n",
    "               node_hidden_sizes = [config.node_geometry_feat_dim, config.node_state_dim * 2],\n",
    "               n_prop_layers = 5,\n",
    "               share_prop_params=False,\n",
    "               #edge_net_init_scale=0.1,\n",
    "               node_update_type='residual',\n",
    "               use_reverse_direction=False,\n",
    "               reverse_dir_param_different=False,\n",
    "               layer_norm=False,\n",
    "               similarity='dotproduct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memanuel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/emanuel/Documents/thesis/layoutgmn_reproductions/LayoutGMN-pytorch/training_scripts/wandb/run-20231025_133125-t4zgoyz5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts/runs/t4zgoyz5' target=\"_blank\">lively-morning-3</a></strong> to <a href='https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts' target=\"_blank\">https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts/runs/t4zgoyz5' target=\"_blank\">https://wandb.ai/emanuel/LayoutGMN-pytorch-training_scripts/runs/t4zgoyz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded pretrained model to:  ./artifacts/gmn_model_l3s1sr0w:v34/gmn_tmp_model166.pkl (wandb reference: layout_gmn/gmn_model_l3s1sr0w:v34)\n"
     ]
    }
   ],
   "source": [
    "wandb.init(\"layoutgmn_compute_triplet_accuracy\", resume=True)\n",
    "\n",
    "pretrained_path, starting_epoch = download_model_weights_from_wandb(\"layout_gmn/gmn_model_l3s1sr0w:v34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained models\n",
      "Finished loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "loaded_gmn_model = load_pretrained_model(gmn_net, pretrained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_triplets_csv = \"/media/emanuel/8de37f61-64a8-4a87-8e84-52eef99e123a/thesis/mscemanuelkuhn/code/evaluation/test_triplets/triplets_apn_iou.csv\"\n",
    "\n",
    "test_triplets = pd.read_csv(test_triplets_csv).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "info = pickle.load(open('../training_scripts/layoutgmn_data/FP_box_info_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.inference_module_ui import get_batch_sg_data, data_input_to_gmn, reshape_and_split_tensor, compute_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 68161, 'positive': 40097, 'negative': 66563}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_triplets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<inference.inference_module_ui.get_batch_sg_data at 0x7f145a51cdc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_getter = get_batch_sg_data(68161, [40097, 66563], 4,\n",
    "                                         config, info)\n",
    "\n",
    "data_getter\n",
    "\n",
    "# sg_data_a = data['sg_data_a']\n",
    "# sg_data_fp_1 = data['sg_data_p']\n",
    "# sg_data_fp_2 = data['sg_data_n']\n",
    "\n",
    "# assert len(sg_data_a) == len(sg_data_fp_1) == len(sg_data_fp_2)\n",
    "\n",
    "# assert len(sg_data_a) > 0, f\"sg_data_a is empty for {query_fp=}; {sg_data_a=}\"\n",
    "\n",
    "# Graph_Data_dict = data_input_to_gmn(config, self.device,\n",
    "#                                     sg_data_a, sg_data_fp_1, sg_data_fp_2).quadruples()\n",
    "# graph_vecs = self.loaded_gmn_model(**Graph_Data_dict)\n",
    "# x1, y, x2, z = reshape_and_split_tensor(graph_vecs, 4)\n",
    "\n",
    "# sim_1 = compute_similarity(self.config, x1, y) # these are now list of tensors \\n;\n",
    "# # previously there was torch.mean at the start of the RHS\n",
    "# sim_2 = compute_similarity(self.config, x2, z) # list of tensors\n",
    "\n",
    "# sim_val_list_1.append(-(sim_1.cpu().detach().numpy()))\n",
    "# sim_val_list_2.append(-(sim_2.cpu().detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_for_triplet(triplet):\n",
    "    triplet = {key: str(value) for key, value in triplet.items()}\n",
    "\n",
    "    queries = [data_getter.get_graph_data_by_id(triplet[\"anchor\"])]\n",
    "    pos = [data_getter.get_graph_data_by_id(triplet[\"positive\"])]\n",
    "    negs = [data_getter.get_graph_data_by_id(triplet[\"negative\"])]\n",
    "\n",
    "    data_getter.batch_sg(queries)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    data['sg_data_a'] = data_getter.batch_sg(queries)  # , max_box_len_a)\n",
    "    data['sg_data_p'] = data_getter.batch_sg(pos)  # , max_box_len_p)\n",
    "    data['sg_data_n'] = data_getter.batch_sg(negs)  # , max_box_len_n)\n",
    "\n",
    "    assert len(data['sg_data_a']) == len(data['sg_data_p']) == len(data['sg_data_n'])\n",
    "    assert len(data['sg_data_a']) > 0, f\"sg_data_a is empty for; {data['sg_data_a']=}\"\n",
    "\n",
    "\n",
    "    graph_data_dict = data_input_to_gmn(config, \"cpu\",\n",
    "                                        data['sg_data_a'], data['sg_data_p'], data['sg_data_n']).quadruples()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        graph_vecs = loaded_gmn_model(**graph_data_dict)\n",
    "        x1, y, x2, z = reshape_and_split_tensor(graph_vecs, 4)\n",
    "\n",
    "        sim_1 = compute_similarity(config, x1, y) # these are now list of tensors \\n;\n",
    "        # previously there was torch.mean at the start of the RHS\n",
    "        sim_2 = compute_similarity(config, x2, z) # list of tensors\n",
    "    \n",
    "    return sim_1.item(), sim_2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/emanuel/8de37f61-64a8-4a87-8e84-52eef99e123a/thesis/mscemanuelkuhn/code/evaluation/test_triplets/triplets_apn_iou.csv'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_triplets_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute triplet accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 945, 0.746031746031746)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for triplet in test_triplets:\n",
    "    try:\n",
    "        sim_1, sim_2 = compute_for_triplet(triplet)\n",
    "\n",
    "        # print(f\"{sim_1=}, {sim_2=}, {sim_1 > sim_2=}\")\n",
    "\n",
    "        if sim_1 > sim_2:\n",
    "            correct += 1\n",
    "        \n",
    "        total += 1\n",
    "    except:\n",
    "        # print(\"failed\")\n",
    "        continue\n",
    "\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triplet accuracy of this model that was trained for 166 epochs is 0.746, which is a lot lower than reported in the layoutgmn paper (97.54 for the IoU based triplets, which I think are sampled in a similar fashion to the triplets used in this notebook.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
